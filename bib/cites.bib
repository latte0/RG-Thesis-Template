
@article{ReLU,
    title = {Deep Sparse Rectifier Neural Networks},
    author = {Xavier. Glorot and Antoine. Bordes},
    howpublished = {\url{http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf}},
    year = 2011,
    journal = {14th International Conference on Artificial Intelligence and Statistics}
}

@article{Mish,
    title = {Mish: A Self Regularized Non-Monotonic Activation Function},
    author = {Diganta. Misra},
    howpublished = {\url{https://arxiv.org/pdf/1908.08681.pdf}},
    journal = { BMVC 2020}
}





@article{study_af,
    title = {THE STUDY OF ACTIVATION FUNCTIONS IN DEEP LEARNING FOR PEDESTRIAN DETECTION AND TRACKING},
    howpublished = {\url{https://www.researchgate.net/publication/332975597_THE_STUDY_OF_ACTIVATION_FUNCTIONS_IN_DEEP_LEARNING_FOR_PEDESTRIAN_DETECTION_AND_TRACKING}},
    author = {M. N. Favorskaya and V. V. Andreev},
    year = 2019,
    note = {(Accessed on 02/03/2021)}
}




@Misc{trend_af,
    title = {Activation Functions: Comparison of Trends in Practice and Research for Deep Learning},
    howpublished = {\url{https://arxiv.org/pdf/1811.03378.pdf}},
    author = {Chigozie Enyinna Nwankpa and Winifred Ijomah and Anthony Gachagan and Stephen Marshall},
    year = 2018,
    note = {(Accessed on 02/03/2021)}
}

@article{automatic_af,
    title = {A Methodology for Automatic Selection of Activation Functions to Design Hybrid Deep Neural Networks},
    howpublished = {\url{https://arxiv.org/pdf/1811.03980.pdf}},
    author = {Alberto Marchisio and Muhammad Abdullah Hanif and Semeen Rehman and Maurizio Martina and Muhammad Shafique},
    year = 2018,
    journal = {KDD '20: 26th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningAugust, 2020, Pages 1521–1531}
}




@article{evo_af,
    title = {Evolutionary Optimization of Deep Learning Activation Functions},
    howpublished = {\url{https://arxiv.org/pdf/2002.07224.pdf}},
    author = {Garrett Bingham and William Macke and Risto Miikkulainen},
    journal = {GECCO '20: 2020 Genetic and Evolutionary Computation ConferenceJune 2020 Pages 289–296},
}




@Misc{parametric_af,
    title = {Discovering Parametric Activation Functions},
    howpublished = {\url{https://arxiv.org/pdf/2006.03179.pdf}},
    author = {Garrett Bingham and Risto Miikkulainen},
    note = {ICLR 2021},
    year = 2020
}




@article{isotron,
    title = {The Isotron Algorithm: High-Dimensional Isotonic Regression},
    howpublished = {\url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.414.453&rep=rep1&type=pdf}},
    author = {Adam Tauman Kalai and Ravi Sastry},
    journal = {In COLT '09},
    year = 2009
}




@article{efficient_sim,
    title = {Efficient Learning of Generalized Linear and Single Index Models with Isotonic Regression},
    howpublished = {\url{https://arxiv.org/pdf/1104.2018.pdf}},
    author = {Sham Kakade and Adam Tauman Kalai and Varun Kanade and Ohad Shamir},
    journal = {NIPS'11: 24th International Conference on Neural Information Processing Systems, Pages 927–935},
    year = 2011
}




@Misc{lsim,
    title = {Learning Single Index Models in High Dimensions},
    howpublished = {\url{https://arxiv.org/pdf/1506.08910.pdf}},
    author = {Ravi Ganti and Nikhil Rao and Rebecca M. Willett and Robert Nowak},
    year = 2015
}




@article{sim,
    title = {Nonlinear generalization of the monotone single index model},
    howpublished = {\url{https://arxiv.org/pdf/1902.09024.pdf}},
    author = {Zeljko Kereta and Timo Klock and Valeriya Naumova},
    journal = {	Information and Inference: A Journal of the IMA (2020)},
    year = 2019
}



@article{ichimura,
    title = {OPTIMAL SMOOTHING IN SINGLE INDEX MODEL},
    howpublished = {\url{https://projecteuclid.org/download/pdf_1/euclid.aos/1176349020}},
    author = {Hidehiko Ichimura and Wolfgang Hardle and Peter Hall},
    journal = {J. Econometrics, 58(1-2):71–120},
    year = 1993
}



@Misc{Evolving,
    title = {Evolving Normalization-Activation Layers},
    howpublished = {\url{https://arxiv.org/pdf/2004.02967.pdf}},
    author = {Hanxiao Liu and Andrew Brock and Karen Simonyan and Quoc V. Le},
    note = {NeurIPS},
    year = 2020
}



@Misc{swish,
    title = {SEARCHING FOR ACTIVATION FUNCTIONS},
    howpublished = {\url{https://arxiv.org/pdf/1710.05941.pdf}},
    author = {Prajit Ramachandran and Barret Zoph and Quoc V. Le},
    note = {ICLR},
    year = 2018
}




@Misc{init_sparse,
    title = {Deep learning via Hessian-free optimization},
    howpublished = {\url{https://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf}},
    author = {James Martens},
    journal = {ICML 2010},
    year = 2010
}



@article{leaky_relu,
    title = {Empirical Evaluation of Rectified Activations in Convolutional Network},
    howpublished = {arXiv preprint arXiv:1505.00853},
    author = {Bing Xu and Naiyan Wang and Tianqi Chen and Mu Li},
    year = 2015
}

@article{elu,
    title = {FAST AND ACCURATE DEEP NETWORK LEARNING BYEXPONENTIAL LINEAR UNITS (ELUS)},
    howpublished = {\url{https://arxiv.org/pdf/1511.07289.pdf}},
    author = {Djork-Arne Clevert and Thomas Unterthiner and Sepp Hochreiter},
    year = 2016,
    journal = {ACM SE '19: 2019 ACM Southeast Conference, Pages 164–167}
}


@article{selu,
    title = {Self-Normalizing Neural Networks},
    howpublished = {\url{https://arxiv.org/pdf/1706.02515.pdf}},
    author = {Günter Klambauer and Thomas Unterthiner and Andreas Mayr},
    journal = {Advances in Neural Information Processing Systems 30 (NIPS 2017)}
}



@article{klein,
    title = {An Efficient Semiparametric Estimator for Binary Response Models},
    howpublished = {\url{https://www.jstor.org/stable/2951556?seq=1}},
    author = {Roger W. Klein and Richard H. Spady},
    journal = {Econometrica, 1993, vol. 61, issue 2, 387-421},
    year = 1993
}



@Misc{adam,
    title = {Adam: A Method for Stochastic Optimization},
    howpublished = {\url{https://arxiv.org/abs/1412.6980}},
    author = {Diederik P. Kingma and Jimmy Ba},
    note = {ICLR (Poster) 2015}
}


@Misc{momentum,
    title = {On the momentum term in gradient descent learning algorithms. Neural networks :the official journal of the International Neural Network Society, 12(1):145–151, 1999.},
    howpublished = {\url{https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.5612&rep=rep1&type=pdf}},
    author = {Ning Qian},
    year = 1999
}



@Misc{rmsprop,
    title = {RMSProp and equilibrated adaptive learning rates for non-convex optimization},
    howpublished = {\url{http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf}},
    author = {Geoffrey Hinton and Nitish Srivastava and Kevin Swersky},
    year = 2012,
    note = {(Accessed on 02/03/2021)}
}





@Misc{adagrad,
    title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
    howpublished = {\url{https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf}},
    journal = {Journal of Machine Learning Research 12 (2011) 2121-2159},
    author = {John Duchi and Elad Hazan and Yoram Singer},
    year = 2011
}





@Misc{kernel_density,
    title = {Pattern Classification and scene analysis},
    author = {Richard O. Duda and Peter E. Hart},
    publisher = {John Wiley \& Sons, Inc.},
    year = 1973
}





@article{xavier,
    title = {Understanding the difficulty of training deep feedforward neural networks},
    author = {Xavier Glorot and Yoshua Bengio},
    howpublished = {\url{http://proceedings.mlr.press/v9/glorot10a.html}},
    journal = {JMLR Workshop and Conference, 9:249-256, 2010.},
    year = 2010
}


@article{kaiming,
    title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
    author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    howpublished = {\url{https://arxiv.org/abs/1502.01852}},
    journal = {ICCV '15: 2015 IEEE International Conference on Computer Vision (ICCV)December 2015 Pages 1026–1034},
    year = 2015
}



@Misc{pytorch,
    title = {Pytorch},
    howpublished = {\url{https://pytorch.org/}},
    year = 2021,
    note = {(Accessed on 02/03/2021)}
}


@Misc{chainer,
    title = {Chainer: A flexible framework for neural networks},
    howpublished = {\url{https://chainer.org/}},
    year = 2021,
    note = {(Accessed on 02/03/2021)}
}


@Misc{scikit-learn,
    title = {scikit-learn Machine Learning in Python},
    howpublished = {\url{https://scikit-learn.org/stable/}},
    year = 2021,
    note = {(Accessed on 02/03/2021)}
}



@Misc{tensorflow,
    title = {Tensorflow},
    howpublished = {\url{https://www.tensorflow.org/}},
    year = 2021,
    note = {(Accessed on 02/03/2021)}
}



@Misc{resnet50,
    title = {Deep Residual Learning for Image Recognition},
    author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    howpublished = {arXiv preprint arXiv:1512.03385},
    year = 2015,
}




@Misc{gui,
    title = {プログラミング不要！ 約50のAI構築GUIツールをまとめたサービスマップを公開！},
    howpublished = {\url{https://ainow.ai/2019/07/09/173221/}},
    year = 2019,
    author = {いっしー},
    note = {(Accessed on 02/03/2021)}
}




@Misc{sony,
    title = {Neural Network Console},
    author = {株式会社SONY},
    howpublished = {https://dl.sony.com/}},
    year = 2019,
    note = {(Accessed on 02/03/2021)}
}


@article{gan,
    title = {Generative Adversarial Networks},
    author = {an J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
    howpublished = {\url{https://arxiv.org/abs/1406.2661}},
    journal = {Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp. 2672–2680}
}


@Misc{rnn,
    title = {Learning internal representations by error propagation},
    author = {D. E. Rumelhart and G. E. Hinton and R. J. Williams},
    howpublished = {\url{https://apps.dtic.mil/dtic/tr/fulltext/u2/a164453.pdf}},
    year = 1985,
    note = {ICS Report 8506},
}

@Misc{zero,
  author = {斎藤 康毅},
  publisher = {オライリー・ジャパン},
  title = {ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装},
  year = {2016},
}

@Misc{xavier_taco,
  author = {nTaco},
  title = {Xavierの初期化 (Xavier Initialization)},
  howpublished = {\url{https://ntacoffee.com/xavier-initialization/}},
  year = {2021},
  note = {(Accessed on 02/03/2021)}
}

@Misc{kaiming_taco,
  author = {nTaco},
  title = {Kaimingの初期化 (Kaiming Initialization)},
  howpublished = {\url{https://ntacoffee.com/kaiming-initialization/}},
  year = {2021},
  note = {(Accessed on 02/03/2021)}
}


@Misc{rmsprop_wakaru,
  author = {omiita},
  title = {【2020決定版】スーパーわかりやすい最適化アルゴリズム -損失関数からAdamとニュートン法-},
  howpublished = {\url{https://qiita.com/omiita/items/1735c1d048fe5f611f80#:~:text=RMSPropはgradの大き,調整する、というものです。}},
  year = {2020},
  note = {(Accessed on 02/03/2021)}
}