深層ニューラルネットワークの研究者らは複雑なデータに対する適合度の高さを向上さ せることに注力してきたため, 信頼区間の研究はあまり行われてこなかった.


 一方で確率 論を用いた機械学習は生物学研究や自動運転の制御における意思決定のために信頼区間 を提供している.

 これは機械学習の利用者にその手法の出力の確からしさの判断基準をも たらしている.

 この確からしさを用いることで利用者はある手法を利用する際にデータが 不足しているのか, 違うモデルを使うべきか, 出力を信頼することができるかとといった 判断をする指標にすることができる


. 複雑なデータに適合する深層ニューラルネットワー クと意思決定に有用な情報を提供する信頼区間の推定という 2 つのアプローチの利点を活 用するため, 本研究では深層ニューラルネットワークの部分集合である深層生成モデルに おける信頼区間推定の研究を行う.


信頼区間を提供することのできる手法の１つとしてガウス過程回帰モデルが挙げられ る.

 ガウス過程回帰は少ないパラメータから精度の高い推定ができるという特徴を持って いたが, データ数に比例する大きさの行列の逆行列を計算しなければならず, 大規模デー タに対して適用できないという問題があった.

近年, 大規模なデータに適用できるようガ ウス過程回帰の良い近似手法が提案され, 応用の幅が広がってきた.

これらの近似手法で は従来必要であったデータ数に比例する大きさの行列の逆行列の計算をより小さな行列の 逆行列から近似することを試みている.

またガウス過程を用いて教師なし学習を行う手法 としてガウス過程潜在変数モデルが提案されている.

深層ニューラルネットワークは高次元データに対してより高い精度での教師あり学習を 行う機械学習手法として発展を遂げ, 画像認識や自然言語処理の分野で以前の手法では解 くことのできなかった問題を次々と解いてきた [1].

それらの中には人間を凌駕する精度 での画像中の物体認識や自然言語理解といったものが含まれている.

深層ニューラルネッ トワークが成果を上げるとともに実社会における応用が取り沙汰されるようになり, 応用 における問題点が浮き彫りとなってきた. Marcus[2] は現在の深層ニューラルネットワー クはあらかじめ想定された入力のみを仮定できる安定した環境においてのみ有効に動作す ると主張している.

また Goodfellow によれば Adversrial Example[3] と呼ばれるニューラ 1 第 1 章 序論 ルネットワークに誤認識をさせる画像を意図的に生成できるという脅威が存在している.

信頼区間が計算可能な深層ニューラルネットワークの研究はこれらの問題の解決を試みて いる [4].


深層ニューラルネットワークは教師あり学習だけではなく, 生成モデルを用いて正解ラ ベルを使わずにデータの特徴量を獲得する教師なし学習においても利用されている.


 この ようにデータの生成過程をモデル化する深層ニューラルネットワークは深層生成モデルと 呼ばれており, 代表的な深層生成モデルとして GAN や VAE, Glow などが挙げられる. 深 層生成モデルは深層ニューラルネットワークとともに発展し, 高解像度の画像や動画, 文 章などの生成や編集をすることができるようになった.


深層生成モデルにおいても深層ニューラルネットワークと同様の問題点がある.

 Nalisnick[5] は Glow や VAE において分布外の入力に対して高い尤度で推定を行なってしまうという 脆弱性を報告している.

 具体的には標識に書かれた番地の画像からなるデータセットであ る SVHN データセットで学習した生成モデルが犬や猫, 人などの一般的なデータセットの 画像に対して高い尤度を割り当ててしまう.

 Tabacof[6] は VAE に対して, 入力画像をまっ たく別の画像と認識してしまう Adverserial Image を生成する方法を提案している.

 信頼区間が提供できる深層ニューラルネットワークのためにガウス過程とニューラル ネットワークの関係性の研究が進められている. Neal[7] によって一層の無限次元の幅の隠 れ層を持つニューラルネットワークにおける推論がガウス過程回帰と数学的に等価である ことが示された.

その後, Lee ら [8] によって多層の全結合層を持つニューラルネットワー ク, Alonso ら [9] によって深層畳み込みニューラルネットワーク, Yang[10] によってより広 範なアーキテクチャを持つ深層ニューラルネットワークに対する等価性が示されている.

 このように教師あり学習という文脈におけるニューラルネットワークとガウス過程の 等価性が議論されてきた一方で, 教師なし学習という枠組みでの議論はほとんどされてこ なかった. ガウス過程を用いた教師あり学習であるガウス過程回帰が単純な行列演算のみ で推論が行えるのに対して, ガウス過程を用いた教師なし学習ではカーネル関数に対する バックプロパゲーションの演算や期待値の計算を行い勾配法によって最適化するという過 程を経る必要があるなど非常に複雑な計算を伴う.

そのためガウス過程によって深層生成 モデルを構築するという研究にはこれらの課題を解決する必要があった.

本研究ではガウス過程を用いて教師なし学習を行うベイズ深層生成モデルを構築する. ガウス過程による教師なし学習を行う生成モデルであるガウス過程潜在変数モデルを深 層化することによって深層生成モデルを構築する.

ガウス過程潜在変数モデルでは利用す るカーネルの期待値を解析的に計算する必要があった.

 ガウス過程による深層ニューラル ネットワークのために使われる深層カーネルの期待値は解析的に計算することは困難であ る.

これを近似計算によって計算可能にすることで, ガウス過程潜在変数モデルを深層化 した. 提案手法がベイズ深層生成モデルとして有効に機能することをいくつかの実験を用いて 示した.

まず, 提案手法によって獲得したデータの特徴量がデータを分類するのに有益で あるかを潜在変数空間上で K 近傍法を用いて分類問題を学習させることにより評価する.

次に, 従来の深層ニューラルネットワークとガウス過程の研究 [8] で行われた実験に従い, 特徴量空間における信頼区間がモデルの出力の確からしさを表しているかをテストデー 2 第 1 章 序論 タにおける正解データと不正解データの信頼区間を比較し, 観察する. 最後に生成データ 空間における信頼区間がモデルの出力の確からしさを表しているかを真のデータ分布と の比較によって検証する.

本研究における主な貢献を以下にまとめる. •

 近似手法を用いた期待値計算によって深層構造を持つガウス過程潜在変数モデルを 構築した. •
 教師なし学習を行えるベイズ深層生成モデルの実現した. • 実験により, 従来の深層生成モデルよりも高い精度で推定できることを示した. •
 実験により, 従来の深層生成モデルと比較し安定的に学習できることを示した. • 実験により, 従来の深層生成モデルと異なり出力が不確かさを表していることを示 した.
 1.2 本論文の構成 本論文における第 2 章以降の構成は次の通りである. 第 2 章では, はじめにガウス過程, 生成モデル, 深層ニューラルネットワーク, 深層生成 モデルといった本研究へと繋がるいくつかの機械学習手法やモデルを解説し,
これらの手 法の課題を洗い出す. また, その課題を解決することによって得られる効用を示し, 本研 究の立場を明確化する. 第 3 章では, まず, 提案手法の元となるガウス過程及びガウス過 程潜在変数モデルを導入する. そして生成を行う深層ニューラルネットワークがガウス過 程潜在変数モデルとしてみなせることを示し, 提案手法の詳細を述べる. 第 4 章では, 第 3 章で述べた手法の実装, 第 5 章で行う実験で用いたデータセット, 実装における留意点に ついて述べる. 第 5 章では, 第 1 章で求められた先行研究における課題を提案手法が解決 していること示すために行った実験について述べる. 第 6 章では, 実験の結果に対する考 察を行い, 本研究を行う上で浮上した提案手法の限界を示し, 今後の研究方針についてま とめる.
