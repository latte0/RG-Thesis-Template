ディープラーニングの活性化関数に関する最近の研究はまだ多く、様々な実験が 行われている。

ディー

ディープラーニングの活性化関数において一般的に使われているものとして、reluやsigmoid等の活性化関数が挙げられる。

ディープラーニングの活性化関数の一つであるReLUに関する最近の研究は、M.N .Favorskaya (2020)によって行われており、Favorskaya (2020)では多くの実験が行われている。また、Chigozie Enyinna Nwankpa (2018)では、VGGNetやALexNetなどの多くの人気のあるディープラーニングの出力の活性化関数や、dSiLUなどのSigmoid関数よりも優れた関数が使用されています。しかし、両者を見ても、経験的に活性化関数を選択しているに過ぎず、どのような状況下でも 適切な活性化関数をどのように選択するかについては一般化されておらず、議論の余地が残されています。また、アルバート・マルキシオ（2018）は、既存の活性化関数の中から最適な活性化関数を見出しています。しかし、その選択は、すでに知られているものから関数全体を選択している。Garrett Bingham（2020）は、内部から探索することはできなかったようです。 多くのハイパーパラメータを持つ活性化関数を選択し、訓練で推定することで精度が向上します。しかし、これも関数全体の探索には程遠い。

より良い活性化関数を選択して精度を向上させ、パラメータ数を減らすことは、より良いモデルを学習・発見するための重要な課題です。

一方、統計学の世界に目を向けると、GLM（Generalized Linear Model）やSIM（single index model）などの線形回帰の一般化が提案されている。これら2つのモデルは、E[Y|X] = X ⋅ w の線形回帰モデルに

E[Y|X] = g -1 (X ⋅ w)で表されます。

の形で表されます。

Logitが有名で、ディープラーニングではシグモイド関数として応用されています。一方、SIMのはリンク関数gの推定にノンパラメトリックな手法を用いており ディープラーニングには応用されていないようです。また、SIM'sの経験的に推定可能な反復学習 LPAVアルゴリズムと呼ばれるL-isotron法がSham Kakade(2011)で紹介されている。しかし、LPAVでは線形相補的な位置推定法を用いてデータを並べ替えるため、ディープラーニングのような重い計算には不向きである。また、活性化関数に対応するリンク関数が未知の場合には、カーネル推定などのリンク関数をノンパラメトリックに推定する方法が市村(1993)によって提案されている。しかし，リンク関数を全データセットに対して推定するため，データ数が多い場合でもディープラーニング的な効果は得られない．Klein and Spady（1993）の二項選択モデルも同様の手法である。カーネル関数を用いたノンパラメトリックな方法で提案されているが、この方法による深層学習については研究されていない。

www.DeepL.com/Translator（無料版）で翻訳しました。
