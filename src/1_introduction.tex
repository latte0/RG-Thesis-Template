\chapter{序論}
\label{introduction}

本章ではまず, 本研究を取り巻く社会の背景について述べる. そして本研究の解決する
課題及び課題を解決する意義, 解決するための手法を提示する. 最後に本論文の構成を外
観し, 序論を締める.

\section{はじめに}
\label{introduction:background}

\subsubsection{背景}
近年機械学習では、ニューラルネットワークにおける活性化関数として、シグモイド関数やReLU関数~\cite{ReLU}などの一般的に用いられてきた。
ニューラルネットワークにおける活性化関数は、その種類や問題に応じて最適な活性化関数を経験則に基づいて調整していた。
一方，統計学の分野では，リンク関数が未知の場合には，カーネル関数を用いてノンパラメトリックに推定するという手法が推定されている。

\subsubsection{課題、手法}
以下の課題を解決する。
\begin{itemize}
  \item 人が調整する部分LRやハイパーパラメータ等がすくなるなる
  \item デーセットの形を理解しなくて良くなる。
\end{itemize}
そこで本論文は事前に関数の形を指定しないカーネル関数を用いた活性化関数を提案する。

\subsubsection{構成外観}

さらに、実際のデータセットを用いて、ニューラルネットワークの出力層を本論文で提案する方法に置き換えることにより従来の活性化関数と同等かそれ以上の精度で予測できること示した。
本研究における主な貢献を以下にまとめる.

\begin{itemize}
  \item カーネル関数を用いた汎用的な活性化関数で実用的なものを完成させた。
  \item Kernel AFはさまざまなデータセットにおいて既存の活性化関数によりより良い精度を出すことを達成した。
  \item Kernel AFはいくつかのデータセットでは高いLRでも安定した学習精度を出すことに成功した。
  \item Kernel AFを用いることによりデータセットに応じて出力層の活性化関数の形は従来のものではないことを示した。
  \item Kernel AFが勾配消失しないための条件を探求した。
\end{itemize}


なお，Bitcoin~\cite{Bitcoin}は関係ない．

\section{本論文の構成}

本論文における以降の構成は次の通りである．

~\ref{background}章では，ノンパラメトリックモデル、カーネル法などといった本研究へとつながる背景の解説し、これらの手法における課題を洗い出す。
~\ref{proposed}章では，本研究におけるカーネル法を用いた活性化関数についての解説を行い、提案手法の解説の詳細を述べる。
~\ref{implementation}章では，~\ref{proposed}章で述べた手法の実装及び、実装における留意点と．
~\ref{evaluation}章では，\ref{issue}章で求められた課題に対しての評価を行い，考察する．
~\ref{conclusion}章では、実験の結果に対する考察を行い,本研究を行う上で浮上した提案手法の限界を示し,今後の研究方針についてまとめる






%%% Local Variables:
%%% mode: japanese-latex
%%% TeX-master: "../thesis"
%%% End:
