\chapter{序論}
\label{introduction}

本章ではまず, 本研究を取り巻く社会の背景について述べる. そして本研究の解決する
課題及び課題を解決する意義, 解決するための手法を提示する. 最後に本論文の構成を外
観し, 序論を締める.

\section{はじめに}
\label{introduction:background}

\subsubsection{背景}


近年、画像認識や音声認識といった分野で機械学習の中でもディープラーニングと呼ばれる分野が急速発展し、自動運転やスマートスピーカーといったプロダクトとして人々の日常の中にも応用され始めている。
機械学習はプログラミングを容易にするPytorchやTensorflowと呼ばれるライブラリの開発も積極的に行われており、非エンジニアにも使いやすいソニーのNeural Network Consoleなどといったツールなども登場している。
これらは機械学習におけるニューラルネットワークの構築を容易にするだけではなく、学習アルゴリズム自体も抽象化され複雑な数式を理解せずとも使用できるようになっている。
ニューラルネットワークを構築する重要な要素の一つに活性化関数がある。
この活性化関数には、シグモイド関数やReLU関数~\cite{ReLU}などの一般的に用いられてきた。
そしてこれらは問題やデータに応じて最適な活性化関数を経験則に基づいて調整していた。
また、ニューラルネットワークでは特に出力層のアウトプットを考慮した活性化関数の組み合わせを採択することが多く、例えばResnet50では、
問題が分類ということを考慮され、中間層は全てReLU、出力層はシグモイドなどといった組み合わせが使用されている。

一方，統計学の分野では，リンク関数が未知の場合には，ノンパラメトリックな手法に基づきモデルを推論する幾つかの手法が考案されている。
カーネル密度推定を用いてノンパラメトリックに推定するという手法がIchimura~\cite{ichimura}によって提案されている。

\subsubsection{課題・手法}

ニューラルネットワーク構築の際の課題として、問題に応じた最適な活性化関数が未だわかっていないことが挙げられる。
より良い精度を出すために適切な活性化関数を導くことができると良い。
特に出力層に使う活性化関数はデータセットや問題の種類を意識する必要があり、初学者にとっての構築を難しくする。
そこで本論文は事前に関数の形を指定しないカーネル密度推定を用いた活性化関数を提案する。
本間研究ではカーネル密度推定とトレーニングデータのいくつかの点を用いて活性化関数の推論をするアルゴリズムを構築する。
統計学の世界で用いられていた、ノンパラメトリックなリンク関数の推論では、トレーニングデータの全てを使用する必要があったが、ディープラーニングでの応用を考え
計算時間を現実的なものにするため、使用するデータ点を可変にすることが可能なアルゴリズムを提案した。

本論文では以下の課題を解決した。
\begin{itemize}
  \item 出力層に使う活性化関数を状況に応じた適切な形に変わる汎用的な関数を導き、高い精度を出せるようにした。
  \item そのような関数を使うことで、データセットの形等の専門的な知識を理解しなくて済むようになり、ニューラルネットの構築を容易にした。
\end{itemize}

\subsubsection{貢献}

今後本研究で提案するカーネル密度推定を用いた活性化関数をKernel AFと表記する。
Kernel AFは実際のデータセットを用いて、ニューラルネットワークの出力層を本論文で提案する方法に置き換えることにより従来の活性化関数と同等かそれ以上の精度で予測できること示した。
本研究における主な貢献を以下にまとめる.

\begin{itemize}
  \item カーネル密度推定を用いた汎用的な活性化関数で実用的なものを完成させた。
  \item Kernel AFはさまざまなデータセットにおいて既存の活性化関数によりより良い精度を出すことを達成した。
  \item Kernel AFはいくつかのデータセットでは高い学習率でも安定した学習精度を出すことに成功した。
  \item Kernel AFを用いることによりデータセットに応じて出力層の活性化関数の形は従来のものではないことを示した。
  \item Kernel AFが勾配消失しないための条件を探求した。
\end{itemize}


\section{本論文の構成}

本論文における以降の構成は次の通りである．

~\ref{background}章では，ノンパラメトリックモデル、カーネル密度推定などといった本研究へとつながる背景の解説し、これらの手法における課題を洗い出す。
~\ref{proposed}章では，本研究におけるカーネル密度推定を用いた活性化関数についての解説を行い、提案手法の解説の詳細を述べる。
~\ref{implementation}章では，~\ref{proposed}章で述べた手法の実装及び、実装における留意点を述べる。
~\ref{evaluation}章では，\ref{background}章で求められた課題に対しての評価を行い，考察する．
~\ref{conclusion}章では、実験の結果に対する考察を行い,本研究を行う上で浮上した提案手法の限界を示し,今後の研究方針についてまとめる






%%% Local Variables:
%%% mode: japanese-latex
%%% TeX-master: "../thesis"
%%% End:
