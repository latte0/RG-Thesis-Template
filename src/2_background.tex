\chapter{背景}
\label{background}

本章では本研究の背景について述べる.
まず機械学習における活性化関数のの役割について明確にする。
活性化関数について概説し、現在の機械学習における活性化関数の抱える問題点を明らかにする。
次に、活性化関数の他に、ニューラルネットワークにおける精度を向上させるいくつかの構成要素について述べる。
本研究の問題点の解決に必要な、ノンパラメトリックモデルとその具体例であるカーネル法を導入する。
また、統計学において活性化関数に相当する概念がどのように応用されてきたか述べる。
最後に、実社会において機械学習を行う上での問題点や課題を述べ、本研究が取り組むべき課題を明確にする。



\section{活性化関数}

ディープラーニングの活性化関数に関する最近の研究はまだ多く、様々な実験が 行われている。
ディープラーニングの活性化関数の一つであるReLUに関する最近の研究は、M.N .Favorskaya (2020)によって行われており、Favorskaya (2020)では多くの実験が行われている。
また、Chigozie Enyinna Nwankpa (2018)では、VGGNetやALexNetなどの多くの人気のあるディープラーニングの出力の活性化関数や、
dSiLUなどのSigmoid関数よりも優れた関数が使用されています。
しかし、両者を見ても、経験的に活性化関数を選択しているに過ぎず、どのような状況下でも 適切な活性化関数をどのように選択するかについては一般化されておらず、
議論の余地が残されています。また、アルバート・マルキシオ（2018）は、既存の活性化関数の中から最適な活性化関数を見出しています。
 しかし、その選択は、すでに知られているものから関数全体を選択している。Garrett Bingham（2020）は、内部から探索することはできなかったようです。
  多くのハイパーパラメータを持つ活性化関数を選択し、訓練で推定することで精度が向上します。 しかし、これも関数全体の探索には程遠い。
より良い活性化関数を選択して精度を向上させ、パラメータ数を減らすことは、より良いモデルを学習・発見するための重要な課題です。


\section{統計学における位置付け}
　一方、統計学の世界に目を向けると、GLM（Generalized Linear Model）やSIM（single index model）などの線形回帰の一般化が提案されている。
これら2つのモデルは、「」の線形回帰モデルに、「」のリンク機能を持たせたものです。 
 一方、SIM'sではリンク関数gの推定にノンパラメトリックな手法を用いており ディープラーニングには適用されていないようです。
 また、SIM'sの経験的に推定可能な反復学習 LPAVアルゴリズムと呼ばれるL-isotron法がSham Kakade(2011)で紹介されている。 
 しかし、LPAVでは線形相補的な位置推定法を用いてデータを並べ替えるため、ディープラーニングのような重い計算には不向きである。 


\section{ノンパラメトリックモデルとカーネル法}

 また、活性化関数に対応するリンク関数が未知の場合には、カーネル推定などのリンク関数をノンパラメトリックに推定する方法が市村（1993）によって提案されている。
 しかし、リンク関数をデータセット全体で推定するため、ディープラーニング的には データ数が多い場合でも有効ではない。Klein and Spady (1993)の二項選択モデルも同様の手法である．
 カーネル関数を用いたノンパラメトリックな方法で提案されているが、この方法での深層学習については研究されていない。




\section{学習におけるいくつかの知識}
機械学習において精度を向上させる方法は大きく分けると、ラーニングレートの変更
\subsection{ラーニングレート}
学習率はニューラルネットにおけるハイパーパラメータの一つ。入念に調整する必要がある。
\subsection{初期値}
\subsection{レギュラライザー(l1ノルムなど)}
\subsection{optimizer}
この辺について
\section{実社会における学習の問題点}
機械学習を導入するにあたって、データセットに応じたさまざまなメタ的要素の取捨選択が必要となり、

\if0
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.4]{./img/hashrate.png}
        \caption{2017年1月のハッシュレート分布 出典：Blockchain.info\cite{bitcoinhashrate}}
        \label{img:hashrate}
    \end{center}
\end{figure}
\fi
