\chapter{結論}
\label{conclusion}

本章では第5章(\ref{evaluation})の3つの実験の結果に対する考察を行い、第1章\ref{introduction}で述べた貢献\ref{kouken}にどのように繋がったか考える。
そして、提案手法の利点と限界について述べ、今後の課題及び方針を示す。


\section{本研究のまとめ}

カーネルを使った汎用的な関数でニューラルネットの最終層を置き換えることで、実際に精度の向上を図ることができた。

この実験を通して、ReLUやシグモイドと同等かそれ以上の結果が得られていることがわかる。
 実験1(\ref{exp1})によりSigmoidでは精度が低いデータセットやReLUでは精度の低いデータセットでもK-AFはある程度高い精度が出せることがわかった。
これによりデータセットの形を意識せずとも同様の活性化関数を用いても問題なく画集を行えるので、初心者でも気軽に使える活性化関数になったことがわかる。
 実験2(\ref{exp2})により状況に応じた活性化関数の形が実際可視化されることで、既存の活性化関数の有用性を示すだけでなく、
 新たな活性化関数の模索の必要性を示すことができた。
 また、分類系の問題ではSigmoidのような活性化関数でも表現の幅として程度十分であることも可視化され理解することができた。
これらの結果により、ブラックボックス化された活性化関数選択問題の解決に近づいたことがわかる。
 実験3(\ref{exp3})ではこのようなK-AFがどのような場合に勾配発散の少ない有効な活性化関数になるか定量的に示すことができた。



\section{本研究の課題}

\subsection{勾配の発散問題}
複雑なデータセットの場合は、適切にパラメータを調整しなければ、勾配が発散してしまい、適切に学習できない問題が本論文でも挙げられた。
今後は学習を始める際は適当なパラメータでもある程度精度を保障できるようなアルゴリズムへと改良の余地が残されている。

\subsection{ディープラーニングへの応用}
本論文ではK-AFは出力層の活性化関数のみを置き換え精度を上げることに成功した。しかしながら、K-AFのアルゴリズムでは、次の層の正解のラベルデータを必要とするため、
中間層に生かすことができない。より良い精度を出すためには中間層でも使える新しいアルゴリズムが求められる。



\section{将来的な展望}

活性化関数を汎用的に推論するという論文は未だ少なく研究分野として今後非常に注目すべきであると考えている。 
将来的には自動運転などの産業分野においても有用なモデルへの応用されることを望む。
また、K-AFが汎用的な活性化関数の代表として初学者や非エンジニアが扱いやすい道具として応用されることを望む。


%%% Local Variables:
%%% mode: japanese-latex
%%% TeX-master: "../thesis"
%%% End:
