Abstract of Bachelor's Thesis - Academic Year 2020
\begin{center}
\begin{large}
\begin{tabular}{|p{0.97\linewidth}|}
    \hline
      \etitle \\
    \hline
\end{tabular}
\end{large}
\end{center}

~ \\


In recent years, in machine learning, sigmoid functions and ReLU functions have been commonly used as activation functions in neural networks.
The optimal activation function was adjusted empirically according to the type of activation function and the problem.
On the other hand, in the field of statistics, when the link function is unknown, the method of nonparametric estimation using kernel functions has been estimated.
Therefore, this paper proposes an activation function using a kernel function that does not assume the form of the function in advance.
Furthermore, by replacing the output layer of the neural network with the method proposed in this paper using a real data set, it is shown that the prediction accuracy is as good as or better than the conventional activation function.


~ \\
Keywords : \\
\underline{1. Deep lerning},
\underline{2. Activation Function},
\underline{3. Non parametric},
\underline{4. Kernel Function}
\begin{flushright}
\edept \\
\eauthor
\end{flushright}
