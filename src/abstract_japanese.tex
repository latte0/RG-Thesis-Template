卒業論文要旨 - 2020年度 (令和02年度)
\begin{center}
\begin{large}
\begin{tabular}{|M{0.97\linewidth}|}
    \hline
      \title \\
    \hline
\end{tabular}
\end{large}
\end{center}

~ \\



近年機械学習では、ニューラルネットワークにおける活性化関数として、シグモイド関数やReLU関数などが一般的に用いられてきた。
活性化関数は、その種類や問題に応じて最適な活性化関数を経験則に基づいて調整していた。
一方，統計学の分野では，リンク関数が未知の場合には，カーネル関数を用いてノンパラメトリックに推定するという手法が推定されている。
そこで本論文は事前に関数の形を仮定しないカーネル密度推定を用いた活性化関数を提案する。
さらに、実際のデータセットを用いて、ニューラルネットワークの出力層を本論文で提案する手法に置き換えることにより
従来の活性化関数と同等かそれ以上の精度で予測できること示した。


~ \\
キーワード:\\
\underline{1. ディープラーニング},
\underline{2. 活性化関数},
\underline{3. ノンパラメトリック},
\underline{4. カーネル密度推定}
\begin{flushright}
\dept \\
\author
\end{flushright}
